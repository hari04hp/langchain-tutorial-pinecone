{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial Followed from https://python.langchain.com/docs/modules/model_io/chat/function_calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import api_key #my local file\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = api_key.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_1XJuZJA9dEolY4Tm1EKeU7kX', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_28bmMQbGxMaRa6IliQ04w8Ya', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 112, 'total_tokens': 161}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-4cec0147-d412-4972-9066-839ec1e24d88-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_1XJuZJA9dEolY4Tm1EKeU7kX'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_28bmMQbGxMaRa6IliQ04w8Ya'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_1XJuZJA9dEolY4Tm1EKeU7kX'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_28bmMQbGxMaRa6IliQ04w8Ya'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "t = llm_with_tools.invoke(query)\n",
    "print(t)\n",
    "t.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'multiply', 'args': '', 'id': 'call_o7tFeMMudKjyHNbdLXQ9sfAk', 'index': 0}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': ': 3, ', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': '\"b\": 1', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': '2}', 'id': None, 'index': 0}]\n",
      "[{'name': 'add', 'args': '', 'id': 'call_d3lGQ5wxycH8tPiq5RVVPC3P', 'index': 1}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': ': 11,', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': ' \"b\": ', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': '49}', 'id': None, 'index': 1}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "async for chunk in llm_with_tools.astream(query):\n",
    "    print(chunk.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(gathered.tool_call_chunks[0][\"args\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  partial parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(gathered.tool_calls[0][\"args\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing tool outputs to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3VgGaQHNymlWl2GjLq3cb08J', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_0ZwA1CI4RhIMclTWh8UkuLEA', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 112, 'total_tokens': 161}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7faa4c13-5e3c-453d-a342-7614f603b66d-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_3VgGaQHNymlWl2GjLq3cb08J'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_0ZwA1CI4RhIMclTWh8UkuLEA'}]),\n",
       " ToolMessage(content='36', tool_call_id='call_3VgGaQHNymlWl2GjLq3cb08J'),\n",
       " ToolMessage(content='60', tool_call_id='call_0ZwA1CI4RhIMclTWh8UkuLEA')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n",
    " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Dxs9hyOkP9z6uNpU4sqOgVC9', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_xA5iWbmwiDoJdpWhvY4tDu7T', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 112, 'total_tokens': 161}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-648e8578-6c57-47ce-8501-4c764026baa9-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_Dxs9hyOkP9z6uNpU4sqOgVC9'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_xA5iWbmwiDoJdpWhvY4tDu7T'}]),\n",
    " ToolMessage(content='36', tool_call_id='call_Dxs9hyOkP9z6uNpU4sqOgVC9'),\n",
    " ToolMessage(content='60', tool_call_id='call_xA5iWbmwiDoJdpWhvY4tDu7T')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(messages, open('messages.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 * 12 = 36\\n\\n11 + 49 = 60', response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 177, 'total_tokens': 193}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-ac217786-235a-4b8c-8de4-2226e155babc-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_2Ots4e9jqtftnTXxin1NwLCk'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 952, 'b': -20},\n",
       "  'id': 'call_rE1Dj09FZfmPHhztrj7qMeBa'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\n",
    "    \"Whats 119 times 8 minus 20. Don't do any math yourself, only use tools for math. Respect order of operations\"\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\n",
    "        \"What's the product of 317253 and 128472 plus four\", name=\"example_user\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"multiply\", \"args\": {\"x\": 317253, \"y\": 128472}, \"id\": \"1\"}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"16505054784\", tool_call_id=\"1\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[{\"name\": \"add\", \"args\": {\"x\": 16505054784, \"y\": 4}, \"id\": \"2\"}],\n",
    "    ),\n",
    "    ToolMessage(\"16505054788\", tool_call_id=\"2\"),\n",
    "    AIMessage(\n",
    "        \"The product of 317253 and 128472 plus four is 16505054788\",\n",
    "        name=\"example_assistant\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are bad at math but are an expert at using a calculator. \n",
    "\n",
    "Use past tool usage as an example of how to correctly use the tools.\"\"\"\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        *examples,\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_akTJmNcHaddkrQfWMDACABUW', 'function': {'arguments': '{\"a\":119,\"b\":8}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 249, 'total_tokens': 266}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e89ec2b3-e39b-4d22-83b5-29618b94021e-0' tool_calls=[{'name': 'multiply', 'args': {'a': 119, 'b': 8}, 'id': 'call_akTJmNcHaddkrQfWMDACABUW'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_akTJmNcHaddkrQfWMDACABUW'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = {\"query\": RunnablePassthrough()} | few_shot_prompt | llm_with_tools\n",
    "# chain.invoke(\"Whats 119 times 8 minus 20\").tool_calls\n",
    "t = chain.invoke(\"Whats 119 times 8 minus 20\")\n",
    "print(t)\n",
    "t.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are bad at math but are an expert at using a calculator. \\n\\nUse past tool usage as an example of how to correctly use the tools.')), HumanMessage(content=\"What's the product of 317253 and 128472 plus four\", name='example_user'), AIMessage(content='', name='example_assistant', tool_calls=[{'name': 'multiply', 'args': {'x': 317253, 'y': 128472}, 'id': '1'}]), ToolMessage(content='16505054784', tool_call_id='1'), AIMessage(content='', name='example_assistant', tool_calls=[{'name': 'add', 'args': {'x': 16505054784, 'y': 4}, 'id': '2'}]), ToolMessage(content='16505054788', tool_call_id='2'), AIMessage(content='The product of 317253 and 128472 plus four is 16505054788', name='example_assistant'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are bad at math but are an expert at using a calculator. \\n\\nUse past tool usage as an example of how to correctly use the tools.')), HumanMessage(content=\"What's the product of 317253 and 128472 plus four\", name='example_user'), AIMessage(content='', name='example_assistant', tool_calls=[{'name': 'multiply', 'args': {'x': 317253, 'y': 128472}, 'id': '1'}]), ToolMessage(content='16505054784', tool_call_id='1'), AIMessage(content='', name='example_assistant', tool_calls=[{'name': 'add', 'args': {'x': 16505054784, 'y': 4}, 'id': '2'}]), ToolMessage(content='16505054788', tool_call_id='2'), AIMessage(content='The product of 317253 and 128472 plus four is 16505054788', name='example_assistant'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " 'InputType',\n",
       " 'OutputType',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__ror__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '__weakref__',\n",
       " '_abatch_with_config',\n",
       " '_abc_impl',\n",
       " '_acall_with_config',\n",
       " '_atransform_stream_with_config',\n",
       " '_batch_with_config',\n",
       " '_calculate_keys',\n",
       " '_call_with_config',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_get_value',\n",
       " '_init_private_attributes',\n",
       " '_iter',\n",
       " '_lc_kwargs',\n",
       " '_merge_configs',\n",
       " '_transform_stream_with_config',\n",
       " 'abatch',\n",
       " 'abatch_as_completed',\n",
       " 'ainvoke',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'batch_as_completed',\n",
       " 'bind',\n",
       " 'bound',\n",
       " 'config',\n",
       " 'config_factories',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'custom_input_type',\n",
       " 'custom_output_type',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'get_graph',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'input_schema',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'kwargs',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'map',\n",
       " 'name',\n",
       " 'output_schema',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'stream',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'transform',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(llm_with_tools)\n",
    "# llm_with_tools.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\"query\": RunnablePassthrough()} | few_shot_prompt | llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WnAqhfk6miJDBrvT3KBj9bdb', 'function': {'arguments': '{\"a\": 119, \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_YAGA6gXcO0sDwhEvKVgSSMNs', 'function': {'arguments': '{\"a\": 20, \"b\": 0}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 249, 'total_tokens': 298}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5d48a677-f2f6-42bb-8728-9af0800bb33d-0', tool_calls=[{'name': 'multiply', 'args': {'a': 119, 'b': 8}, 'id': 'call_WnAqhfk6miJDBrvT3KBj9bdb'}, {'name': 'add', 'args': {'a': 20, 'b': 0}, 'id': 'call_YAGA6gXcO0sDwhEvKVgSSMNs'}])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = chain.invoke(\"Whats 119 times 8 plus 20\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Whats 119 times 8 minus 20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Whats 119 times 8 minus 20'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4V5nHF6tLS9iwCFvnaQ54WBy', 'function': {'arguments': '{\"a\":119,\"b\":8}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 255, 'total_tokens': 272}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d3c079de-5030-44a4-b87d-fc5ab120288c-0', tool_calls=[{'name': 'multiply', 'args': {'a': 119, 'b': 8}, 'id': 'call_4V5nHF6tLS9iwCFvnaQ54WBy'}]),\n",
       " ToolMessage(content='952', tool_call_id='call_4V5nHF6tLS9iwCFvnaQ54WBy'),\n",
       " AIMessage(content='The result of 119 times 8 minus 20 is 952.', response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 498, 'total_tokens': 514}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-a4090697-7812-4f12-b5a1-9a695815e746-0')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "# # ai_msg = llm_with_tools.invoke(messages)\n",
    "# I tried calling the above prompt with chain\n",
    "ai_msg = chain.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "# messages\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "    ai_msg = chain.invoke(messages)\n",
    "    messages.append(ai_msg)\n",
    "    messages\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one did not work because the chain just tells us which first tool to call but it does not know to execute it, unless we manually do. And when we execute the first tool and expect the chain to give the next AI message with addition tool in tool calls, it just replies with a sentence with question in context. So, let's try this with agents since they can think by themselves on which action to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool-Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt should contain (\"placeholder\", \"{agent_scratchpad}\"), so I'm rewriting the prompt here\n",
    "examples = [\n",
    "    HumanMessage(\n",
    "        \"What's the product of 317253 and 128472 plus four\", name=\"example_user\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"multiply\", \"args\": {\"x\": 317253, \"y\": 128472}, \"id\": \"1\"}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"16505054784\", tool_call_id=\"1\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[{\"name\": \"add\", \"args\": {\"x\": 16505054784, \"y\": 4}, \"id\": \"2\"}],\n",
    "    ),\n",
    "    ToolMessage(\"16505054788\", tool_call_id=\"2\"),\n",
    "    AIMessage(\n",
    "        \"The product of 317253 and 128472 plus four is 16505054788\",\n",
    "        name=\"example_assistant\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are bad at math but are an expert at using a calculator. \n",
    "\n",
    "Use past tool usage as an example of how to correctly use the tools.\"\"\"\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        *examples,\n",
    "        (\"human\", \"{query}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we were using initialize agent to call the inbuilt tools or custom tools. If you implement tool calling, then it will be better to use the new create_tool_calling_agent function, it automatically calls the tools accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 119, 'b': 8}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m952\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `subtract` with `{'a': 952, 'b': 20}`\n",
      "\n",
      "\n",
      "\u001b[0msubtract is not a valid tool, try one of [add, multiply].\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 952, 'b': -20}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m932\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 119 times 8 minus 20 is 932.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Output:   {'query': 'Whats 119 times 8 minus 20', 'output': 'The result of 119 times 8 minus 20 is 932.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "\n",
    "agent = create_tool_calling_agent(llm_with_tools, tools, few_shot_prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_ai_msg = agent_executor.invoke({\"query\" : \"Whats 119 times 8 minus 20\"})\n",
    "\n",
    "print(\"Output:  \", agent_ai_msg)\n",
    "# agent_ai_msg.tool_calls =====> ai_msg from the agent will not have .tool_calls\n",
    "# agent_executor.invoke({\"input\": \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\", })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
